---
title: "ML Introduction and Linear Regression"
excerpt: "Learning Python (010) -- USAhousing"
date: 2020-07-16
tags: [learning, python, coding]
mathjax: "true"
---

*Utilizzo l'environment conda py3*  
```console
~$ conda activate py3
~$ conda deactivate
```

*Versione modulo installato*  
```console
~$ pip show scikit-learn
Name: scikit-learn
Version: 0.23.1
Summary: A set of python modules for machine learning and data mining
Home-page: http://scikit-learn.org
Author: None
Author-email: None
License: new BSD
Location: /home/user/miniconda3/envs/py3/lib/python3.7/site-packages
Requires: scipy, joblib, threadpoolctl, numpy
Required-by:
```

**Machine Learning Process**  
<img src="/assets/images/Python/Course 001/section-014/001_MachineLearningProcess.png" width="400">

## Binary Classification

[HTML Table Generator](https://www.tablesgenerator.com/html_tables)  
[Latex Editor](https://www.codecogs.com/latex/eqneditor.php)  

<table align="center">
<caption>Confusion Matrix</caption>
<thead>
  <tr>
    <th></th>
    <th></th>
    <th colspan="2">Predicted Class</th>
    <th></th>
  </tr>
</thead>
<tbody>
  <tr>
    <td></td>
    <td></td>
    <td>1</td>
    <td>0</td>
    <td></td>
  </tr>
  <tr>
      <td rowspan="2"><b>Actual Class</b></td>
    <td>1</td>
    <td>TP</td>
    <td>FN</td>
      <td><i>(P)</i></td>
  </tr>
  <tr>
    <td>0</td>
    <td>FP</td>
    <td>TN</td>
      <td><i>(N)</i></td>
  </tr>
</tbody>
</table>

$$T = True \\ F = False \\ P = Positive \\ N = Negative$$  

$$\alpha = False Positive Rate = \frac{FP}{FP+TN}$$  

$$\beta = False Negative Rate = \frac{FN}{TP+FN}$$  

$$Accuracy = \frac{TP+TN}{TP+TN+FP+FN} = \frac{TP+TN}{P+N}$$  

$$Precision = Positive Predictive Value = \frac{TP}{TP+FP}$$  

$$Recall = Sensitivity = True Positive Rate = \frac{TP}{TP+FN} = \frac{TP}{P}$$  

$$F_{1}Score = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall} = \frac{2 \cdot TP}{2 \cdot TP+FP+FN}$$  

**Bonus meme**  
<img src="/assets/images/Python/Course 001/section-014/003_ErrorMeme.jpg" width="400">


**Evaluation**  
<img src="/assets/images/Python/Course 001/section-014/002_Evaluation.png" width="400">

## Evaluating Regression

MAE = Mean Absolute Error = $$\frac{1}{n} \sum_{i=1}^{n} \left | y_{i}-\widehat{y}_i  \right |$$  
Poco sensibile agli outliers però rappresenta l'errore medio

MSE = Mean Squared Error = $$\frac{1}{n} \sum_{i=1}^{n} \left ( y_{i}-\widehat{y}_i  \right )^2$$  
Unità di misura al quadrato

RMSE = Root Mean Square Error = $$\sqrt(\frac{1}{n} \sum_{i=1}^{n} \left ( y_{i}-\widehat{y}_i  \right )^2)$$  
Risolve i problemi precedenti  

Se rapportati alla media del fenomeno si ha un'idea migliore di quanto è impattante l'errore rispetto la scala di misura

## Choosing an Algorithm
<img src="/assets/images/Python/Course 001/section-014/004_ChoosingModel.png" width="400">

## Linear Regression


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline
```


```python
# data
USAhousing = pd.read_csv('USA_Housing.csv')
USAhousing.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Avg. Area Income</th>
      <th>Avg. Area House Age</th>
      <th>Avg. Area Number of Rooms</th>
      <th>Avg. Area Number of Bedrooms</th>
      <th>Area Population</th>
      <th>Price</th>
      <th>Address</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>79545.458574</td>
      <td>5.682861</td>
      <td>7.009188</td>
      <td>4.09</td>
      <td>23086.800503</td>
      <td>1.059034e+06</td>
      <td>208 Michael Ferry Apt. 674\nLaurabury, NE 3701...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>79248.642455</td>
      <td>6.002900</td>
      <td>6.730821</td>
      <td>3.09</td>
      <td>40173.072174</td>
      <td>1.505891e+06</td>
      <td>188 Johnson Views Suite 079\nLake Kathleen, CA...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>61287.067179</td>
      <td>5.865890</td>
      <td>8.512727</td>
      <td>5.13</td>
      <td>36882.159400</td>
      <td>1.058988e+06</td>
      <td>9127 Elizabeth Stravenue\nDanieltown, WI 06482...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>63345.240046</td>
      <td>7.188236</td>
      <td>5.586729</td>
      <td>3.26</td>
      <td>34310.242831</td>
      <td>1.260617e+06</td>
      <td>USS Barnett\nFPO AP 44820</td>
    </tr>
    <tr>
      <th>4</th>
      <td>59982.197226</td>
      <td>5.040555</td>
      <td>7.839388</td>
      <td>4.23</td>
      <td>26354.109472</td>
      <td>6.309435e+05</td>
      <td>USNS Raymond\nFPO AE 09386</td>
    </tr>
  </tbody>
</table>
</div>



### EDA


```python
USAhousing.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 5000 entries, 0 to 4999
    Data columns (total 7 columns):
     #   Column                        Non-Null Count  Dtype  
    ---  ------                        --------------  -----  
     0   Avg. Area Income              5000 non-null   float64
     1   Avg. Area House Age           5000 non-null   float64
     2   Avg. Area Number of Rooms     5000 non-null   float64
     3   Avg. Area Number of Bedrooms  5000 non-null   float64
     4   Area Population               5000 non-null   float64
     5   Price                         5000 non-null   float64
     6   Address                       5000 non-null   object 
    dtypes: float64(6), object(1)
    memory usage: 273.6+ KB



```python
# statistiche
USAhousing.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Avg. Area Income</th>
      <th>Avg. Area House Age</th>
      <th>Avg. Area Number of Rooms</th>
      <th>Avg. Area Number of Bedrooms</th>
      <th>Area Population</th>
      <th>Price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5.000000e+03</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>68583.108984</td>
      <td>5.977222</td>
      <td>6.987792</td>
      <td>3.981330</td>
      <td>36163.516039</td>
      <td>1.232073e+06</td>
    </tr>
    <tr>
      <th>std</th>
      <td>10657.991214</td>
      <td>0.991456</td>
      <td>1.005833</td>
      <td>1.234137</td>
      <td>9925.650114</td>
      <td>3.531176e+05</td>
    </tr>
    <tr>
      <th>min</th>
      <td>17796.631190</td>
      <td>2.644304</td>
      <td>3.236194</td>
      <td>2.000000</td>
      <td>172.610686</td>
      <td>1.593866e+04</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>61480.562388</td>
      <td>5.322283</td>
      <td>6.299250</td>
      <td>3.140000</td>
      <td>29403.928702</td>
      <td>9.975771e+05</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>68804.286404</td>
      <td>5.970429</td>
      <td>7.002902</td>
      <td>4.050000</td>
      <td>36199.406689</td>
      <td>1.232669e+06</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>75783.338666</td>
      <td>6.650808</td>
      <td>7.665871</td>
      <td>4.490000</td>
      <td>42861.290769</td>
      <td>1.471210e+06</td>
    </tr>
    <tr>
      <th>max</th>
      <td>107701.748378</td>
      <td>9.519088</td>
      <td>10.759588</td>
      <td>6.500000</td>
      <td>69621.713378</td>
      <td>2.469066e+06</td>
    </tr>
  </tbody>
</table>
</div>




```python
# nomi colonne
USAhousing.columns
```




    Index(['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms',
           'Avg. Area Number of Bedrooms', 'Area Population', 'Price', 'Address'],
          dtype='object')




```python
# pairplot
sns.pairplot(USAhousing)
```




    <seaborn.axisgrid.PairGrid at 0x7ffba0e6db50>




![png](/assets/images/Python/Course 001/section-014/output_21_1.png)



```python
# price distribution
sns.distplot(USAhousing['Price'])
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7ffb7646ef10>




![png](/assets/images/Python/Course 001/section-014/output_22_1.png)



```python
# heatmap
sns.heatmap(USAhousing.corr(), cmap='magma_r', annot=True)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7ffb7645cb50>




![png](/assets/images/Python/Course 001/section-014/output_23_1.png)


### Training Model


```python
# sklearn
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import metrics
```


```python
# X e y
X = USAhousing[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms','Avg. Area Number of Bedrooms', 'Area Population']]
y = USAhousing['Price']
```


```python
# train e test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)
```


```python
# train model
lm = LinearRegression()
lm.fit(X_train,y_train)
```




    LinearRegression()




```python
# intercept
print(lm.intercept_)
```

    -2640159.7968526687



```python
# coefficients
coeff_df = pd.DataFrame(data=lm.coef_,index=X.columns,columns=['Coefficient'])
coeff_df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Coefficient</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Avg. Area Income</th>
      <td>21.528276</td>
    </tr>
    <tr>
      <th>Avg. Area House Age</th>
      <td>164883.282027</td>
    </tr>
    <tr>
      <th>Avg. Area Number of Rooms</th>
      <td>122368.678027</td>
    </tr>
    <tr>
      <th>Avg. Area Number of Bedrooms</th>
      <td>2233.801864</td>
    </tr>
    <tr>
      <th>Area Population</th>
      <td>15.150420</td>
    </tr>
  </tbody>
</table>
</div>



### Predictions


```python
predictions = lm.predict(X_test)
```


```python
# scatterplot predictions
plt.scatter(y_test,predictions,marker='o',edgecolors='black',alpha=0.1,s=20)
```




    <matplotlib.collections.PathCollection at 0x7ffb572f8f50>




![png](/assets/images/Python/Course 001/section-014/output_33_1.png)



```python
# distplot residuals
sns.distplot(y_test-predictions,bins=30, hist_kws=dict(edgecolor="black", linewidth=1))
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7ffb56de2a10>




![png](/assets/images/Python/Course 001/section-014/output_34_1.png)


### Metrics


```python
print('MAE:', metrics.mean_absolute_error(y_test, predictions))
print('MSE:', metrics.mean_squared_error(y_test, predictions))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))
```

    MAE: 82288.22251914944
    MSE: 10460958907.208954
    RMSE: 102278.82922290885



```python
# Explained Variance Score (R^2)
metrics.explained_variance_score(y_test,predictions)
```




    0.9178179926151842



## Boston dataset


```python
# df su cui giocare
from sklearn.datasets import load_boston
boston = load_boston()
print(boston.DESCR)
boston_df = boston.data
```

    .. _boston_dataset:
    
    Boston house prices dataset
    ---------------------------
    
    **Data Set Characteristics:**  
    
        :Number of Instances: 506 
    
        :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.
    
        :Attribute Information (in order):
            - CRIM     per capita crime rate by town
            - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.
            - INDUS    proportion of non-retail business acres per town
            - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
            - NOX      nitric oxides concentration (parts per 10 million)
            - RM       average number of rooms per dwelling
            - AGE      proportion of owner-occupied units built prior to 1940
            - DIS      weighted distances to five Boston employment centres
            - RAD      index of accessibility to radial highways
            - TAX      full-value property-tax rate per $10,000
            - PTRATIO  pupil-teacher ratio by town
            - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
            - LSTAT    % lower status of the population
            - MEDV     Median value of owner-occupied homes in $1000's
    
        :Missing Attribute Values: None
    
        :Creator: Harrison, D. and Rubinfeld, D.L.
    
    This is a copy of UCI ML housing dataset.
    https://archive.ics.uci.edu/ml/machine-learning-databases/housing/
    
    
    This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.
    
    The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic
    prices and the demand for clean air', J. Environ. Economics & Management,
    vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics
    ...', Wiley, 1980.   N.B. Various transformations are used in the table on
    pages 244-261 of the latter.
    
    The Boston house-price data has been used in many machine learning papers that address regression
    problems.   
         
    .. topic:: References
    
       - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.
       - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.
    

